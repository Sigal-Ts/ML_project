{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sigal-Ts/ML_project/blob/main/mta_final_term_exercise_2024_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxEMakEiBTl-"
      },
      "source": [
        "#Final-term exercise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63MGm65eCjRr"
      },
      "source": [
        "#1. Load your libraries here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug3u-V4-BWTi",
        "outputId": "bd499a75-fff0-4e26-b4cf-00e843802525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "!pip install catboost\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cHQNXM3l8L9"
      },
      "source": [
        "#Part A:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoS_ee5wDJDE"
      },
      "source": [
        "#Upload your data file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g0XLs7MDKQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82029d5d-4e55-4c33-f31c-f9532c66d953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import  Dropout, Input\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, Lasso, Ridge\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "pgXIKKfbAbg4",
        "outputId": "5590afca-c935-4b78-ad02-dab286501203"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5a65a974-9a11-4bd8-b88f-e739813b50d2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5a65a974-9a11-4bd8-b88f-e739813b50d2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Apartment Prices.csv to Apartment Prices.csv\n",
            "Saving mushroom_cleaned.csv to mushroom_cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "file = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO-FSmz3DTAj"
      },
      "source": [
        "#2. Read the file into a pandas data frame:\n",
        "Split your data to:\n",
        "\n",
        "a. X: the feature matrix\n",
        "\n",
        "b. y: the label vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-ydbL4lDXIa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ff4aec-a60d-4f96-f02b-8151a0636623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the DataFrame:\n",
            "   cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
            "0          1372          2                2          10     3.807467   \n",
            "1          1461          2                2          10     3.807467   \n",
            "2          1371          2                2          10     3.612496   \n",
            "3          1261          6                2          10     3.787572   \n",
            "4          1305          6                2          10     3.711971   \n",
            "\n",
            "   stem-width  stem-color    season  class  \n",
            "0        1545          11  1.804273      1  \n",
            "1        1557          11  1.804273      1  \n",
            "2        1566          11  1.804273      1  \n",
            "3        1566          11  1.804273      1  \n",
            "4        1464          11  0.943195      1  \n",
            "Features (X):\n",
            "   cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
            "0          1372          2                2          10     3.807467   \n",
            "1          1461          2                2          10     3.807467   \n",
            "2          1371          2                2          10     3.612496   \n",
            "3          1261          6                2          10     3.787572   \n",
            "4          1305          6                2          10     3.711971   \n",
            "\n",
            "   stem-width  stem-color    season  \n",
            "0        1545          11  1.804273  \n",
            "1        1557          11  1.804273  \n",
            "2        1566          11  1.804273  \n",
            "3        1566          11  1.804273  \n",
            "4        1464          11  0.943195  \n",
            "\n",
            "Target variable(y):\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    1\n",
            "Name: class, dtype: int64\n",
            "\n",
            "Number of observations: 54035\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "#Classification task when the prediction variable (label/Y/output).\n",
        "#The data include observations of various mushroom characteristics\n",
        "#and are designed to predict whether a mushroom is poisonous or not- 0:not poisonous, 1:poisonous.\n",
        "df_mushroomCleaned= pd.read_csv(\"mushroom_cleaned.csv\")\n",
        "\n",
        "#Making a copy of the original df.\n",
        "df_mushroomCleanedCo = df_mushroomCleaned.copy()\n",
        "\n",
        "#Display the first rows of the copied DataFrame and the feature.\n",
        "print(\"First few rows of the DataFrame:\")\n",
        "print(df_mushroomCleanedCo.head())\n",
        "\n",
        "#Defining the Target Variable (Label).\n",
        "#The class column from the DataFrame assigns to y.\n",
        "#class represents the label we want to predict- if mushrooms are edible or poisonous.\n",
        "y = df_mushroomCleanedCo['class']\n",
        "\n",
        "#Defining the Features.\n",
        "#Remove the class column to leave only the attribute columns, and assign them to the X variable.\n",
        "X = df_mushroomCleanedCo.drop('class', axis=1)\n",
        "\n",
        "#Displaying the properties and the predictor variable to verify that the split was performed correctly.\n",
        "print(\"Features (X):\")\n",
        "print(X.head())\n",
        "print(\"\\nTarget variable(y):\")\n",
        "print(y.head())\n",
        "\n",
        "#Get the number of observations (samples).\n",
        "num_samples = df_mushroomCleanedCo.shape[0]\n",
        "print(f\"\\nNumber of observations: {num_samples}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5BZb-AnDXnb"
      },
      "source": [
        "#3.A. Check for missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glKyIdt4DcKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0418b796-21ec-4630-f5da-7381d2129cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values per column before inserting missing values:\n",
            "cap-diameter       0\n",
            "cap-shape          0\n",
            "gill-attachment    0\n",
            "gill-color         0\n",
            "stem-height        0\n",
            "stem-width         0\n",
            "stem-color         0\n",
            "season             0\n",
            "class              0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "#Checking to see if there are missing data.\n",
        "print(\"Missing values per column before inserting missing values:\")\n",
        "print(df_mushroomCleanedCo.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYqhzgE8Dkdj"
      },
      "source": [
        "If there are no missing values in your data, follow the next steps:\n",
        "1. uncomment the following function by:\n",
        "\n",
        "  a. selecting all the code in the chunk\n",
        "\n",
        "  b. pressing \"ctrl\"+\"/\" to uncomment all lines\n",
        "2. assign the missing values-containing data to a new variable name (see example below).\n",
        "\n",
        "Say my dataset features is named X.\n",
        "\n",
        "Than the use of the function would be:\n",
        "\n",
        "\n",
        "```\n",
        "X_missing=add_missing_values(X)\n",
        " ```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZLGvx7YIUCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0567a41-a425-4d32-db71-4bfe67c72b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
            "0            1372.0        2.0              2.0        10.0     3.807467   \n",
            "1            1461.0        2.0              2.0        10.0     3.807467   \n",
            "2            1371.0        2.0              2.0        10.0          NaN   \n",
            "3            1261.0        6.0              2.0        10.0     3.787572   \n",
            "4            1305.0        6.0              2.0        10.0          NaN   \n",
            "...             ...        ...              ...         ...          ...   \n",
            "54030          73.0        NaN              3.0         2.0     0.887740   \n",
            "54031          82.0        2.0              3.0         2.0     1.186164   \n",
            "54032          82.0        NaN              3.0         2.0     0.915593   \n",
            "54033          79.0        NaN              3.0         2.0     1.034963   \n",
            "54034          72.0        5.0              3.0         2.0     1.158311   \n",
            "\n",
            "       stem-width  stem-color    season  \n",
            "0          1545.0        11.0  1.804273  \n",
            "1          1557.0        11.0       NaN  \n",
            "2          1566.0        11.0  1.804273  \n",
            "3          1566.0        11.0  1.804273  \n",
            "4          1464.0        11.0  0.943195  \n",
            "...           ...         ...       ...  \n",
            "54030       569.0        12.0  0.943195  \n",
            "54031       490.0        12.0  0.943195  \n",
            "54032       584.0        12.0  0.888450  \n",
            "54033       491.0        12.0  0.888450  \n",
            "54034       492.0         NaN  0.888450  \n",
            "\n",
            "[54035 rows x 8 columns]\n",
            "cap-diameter       5164\n",
            "cap-shape          5007\n",
            "gill-attachment    4965\n",
            "gill-color         5102\n",
            "stem-height        5163\n",
            "stem-width         4969\n",
            "stem-color         5106\n",
            "season             5050\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#your code here, if there are no missing values:\n",
        "#Inserting missing values ​​in the data proactively.\n",
        "def add_missing_values(X):\n",
        "      Col_names = X.columns\n",
        "      X_full=X.to_numpy()\n",
        "      rng = np.random.RandomState(4)\n",
        "      n_samples, n_features = X_full.shape\n",
        "\n",
        "#Add missing values in 75% of the lines.\n",
        "      missing_rate = 0.75\n",
        "      n_missing_samples = int(n_samples * missing_rate)\n",
        "\n",
        "      missing_samples = np.zeros(n_samples, dtype=bool)\n",
        "      missing_samples[:n_missing_samples] = True\n",
        "\n",
        "      rng.shuffle(missing_samples)\n",
        "      missing_features = rng.randint(0, n_features, n_missing_samples)\n",
        "      X_missing = X_full.copy()\n",
        "      X_missing[missing_samples, missing_features] = np.nan\n",
        "      X_missing=pd.DataFrame(X_missing)\n",
        "      X_missing.columns=Col_names\n",
        "      return X_missing\n",
        "X_missing = add_missing_values(X)\n",
        "print(X_missing)\n",
        "print(X_missing.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNhwID7JGHQz"
      },
      "source": [
        "\n",
        "#3.B. Impute the missing values using two different methods and assign the imputed output datasets into variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQDXRX4TIotK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52fc61bc-440e-4f0f-c086-8d73119749fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values Count after using Simple Imputer:\n",
            "cap-diameter       0\n",
            "cap-shape          0\n",
            "gill-attachment    0\n",
            "gill-color         0\n",
            "stem-height        0\n",
            "stem-width         0\n",
            "stem-color         0\n",
            "season             0 \n",
            "\n",
            "Missing Values Count after using KNN Imputer:\n",
            "cap-diameter       0\n",
            "cap-shape          0\n",
            "gill-attachment    0\n",
            "gill-color         0\n",
            "stem-height        0\n",
            "stem-width         0\n",
            "stem-color         0\n",
            "season             0\n"
          ]
        }
      ],
      "source": [
        "def fill_missing_values_simple(X_missing):\n",
        "#Completion of missing values by Simple Imputer.\n",
        "    sImputer = SimpleImputer(strategy=\"mean\")  #Fill in missing values with the mean of each column.\n",
        "    X_new = sImputer.fit_transform(X_missing)  #Calculate column means and fill in missing values.\n",
        "    X_new = pd.DataFrame(X_new, columns=X_missing.columns)  #Convert X_new back to a DataFrame with original column names.\n",
        "    return X_new\n",
        "\n",
        "#Example usage for Simple Imputer.\n",
        "X_new = fill_missing_values_simple(X_missing)\n",
        "print(\"Missing Values Count after using Simple Imputer:\")\n",
        "print(X_new.isnull().sum().to_string(), \"\\n\")  #Check if all the missing data have been handled and print it in a clean format.\n",
        "\n",
        "def fill_missing_values_knn(X_missing):\n",
        "    #Completion of missing values by KNN Imputer.\n",
        "    imputer_knn = KNNImputer(n_neighbors=10)  #KNN uses the ten nearest neighbors to impute missing values.\n",
        "    X_filled_knn = pd.DataFrame(imputer_knn.fit_transform(X_missing), columns=X_missing.columns)  #Fill missing values and save as DataFrame.\n",
        "    return X_filled_knn\n",
        "\n",
        "#Example usage for KNN Imputer.\n",
        "X_filled_knn = fill_missing_values_knn(X_missing)\n",
        "print(\"Missing Values Count after using KNN Imputer:\")\n",
        "print(X_filled_knn.isnull().sum().to_string())  #Check and print missing values count for X_filled_knn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAEMq4hijF84"
      },
      "source": [
        "#3.C. Convert categorical features to dummy variables if number of categories is lower than 5, otherwise remove from data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FGOXjHHjYHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be323c06-5ec2-4b29-c508-7f0e5c908107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The table X_new after Dealing with abnormal values \n",
            "\n",
            "       cap-diameter     cap-shape  gill-attachment    gill-color  \\\n",
            "count  52959.000000  54035.000000     54035.000000  54035.000000   \n",
            "mean     561.053453      4.000428         2.138455      7.331126   \n",
            "std      320.585326      2.058069         2.122273      3.044335   \n",
            "min       27.000000      0.000000         0.000000      0.000000   \n",
            "25%      313.000000      2.000000         0.000000      5.000000   \n",
            "50%      567.348141      5.000000         2.000000      7.331126   \n",
            "75%      745.000000      6.000000         4.000000     10.000000   \n",
            "max     1613.000000      6.000000         6.000000     11.000000   \n",
            "\n",
            "        stem-height    stem-width    stem-color        season  \n",
            "count  53019.000000  53494.000000  53881.000000  54035.000000  \n",
            "mean       0.739626   1028.447189      8.441807      0.952016  \n",
            "std        0.563150    711.269214      3.072811      0.289614  \n",
            "min        0.011511      0.000000      1.000000      0.027372  \n",
            "25%        0.306808    472.000000      6.000000      0.888450  \n",
            "50%        0.672875   1042.000000      8.417748      0.943195  \n",
            "75%        0.986364   1427.000000     11.000000      0.943195  \n",
            "max        2.967900   3225.000000     12.000000      1.804273   \n",
            "\n",
            "Data of missing values ​​of X_new\n",
            "cap-diameter       1076\n",
            "cap-shape             0\n",
            "gill-attachment       0\n",
            "gill-color            0\n",
            "stem-height        1016\n",
            "stem-width          541\n",
            "stem-color          154\n",
            "season                0 \n",
            "\n",
            "The table X_filled_knn after Dealing with abnormal values \n",
            "\n",
            "       cap-diameter     cap-shape  gill-attachment    gill-color  \\\n",
            "count  52977.000000  54035.000000     54035.000000  54035.000000   \n",
            "mean     559.152438      4.003868         2.138503      7.325963   \n",
            "std      332.927079      2.083888         2.152860      3.086300   \n",
            "min       26.000000      0.000000         0.000000      0.000000   \n",
            "25%      296.000000      2.000000         0.000000      5.000000   \n",
            "50%      528.000000      5.000000         1.000000      7.500000   \n",
            "75%      770.000000      6.000000         4.000000     10.000000   \n",
            "max     1613.000000      6.000000         6.000000     11.000000   \n",
            "\n",
            "        stem-height    stem-width    stem-color        season  \n",
            "count  53019.000000  53494.000000  53881.000000  54035.000000  \n",
            "mean       0.739951   1025.250901      8.440424      0.952265  \n",
            "std        0.572830    739.067537      3.118602      0.291708  \n",
            "min        0.011511      0.000000      1.000000      0.027372  \n",
            "25%        0.302829    422.000000      6.000000      0.888450  \n",
            "50%        0.613703    919.000000      9.800000      0.943195  \n",
            "75%        1.026196   1489.000000     11.000000      0.943195  \n",
            "max        2.967900   3225.000000     12.000000      1.804273  \n",
            "Data of missing values ​​of X_filled_knn \n",
            "\n",
            "cap-diameter       1058\n",
            "cap-shape             0\n",
            "gill-attachment       0\n",
            "gill-color            0\n",
            "stem-height        1016\n",
            "stem-width          541\n",
            "stem-color          154\n",
            "season                0 \n",
            "\n",
            "Missing Values Count after using Simple Imputer:\n",
            "cap-diameter       0\n",
            "cap-shape          0\n",
            "gill-attachment    0\n",
            "gill-color         0\n",
            "stem-height        0\n",
            "stem-width         0\n",
            "stem-color         0\n",
            "season             0 \n",
            "\n",
            "Missing Values Count after using KNN Imputer:\n",
            "cap-diameter       0\n",
            "cap-shape          0\n",
            "gill-attachment    0\n",
            "gill-color         0\n",
            "stem-height        0\n",
            "stem-width         0\n",
            "stem-color         0\n",
            "season             0\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "#Identify categorical columns:\n",
        "categorical_cols = X_new.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "#If a column has more than 4 different categories, it is removed from the df_filled_mean and df_filled_knn data frames.\n",
        "    if X_new[col].nunique() > 4 or X_filled_knn[col].nunique() > 4:\n",
        "        X_new = X_new.drop(col, axis=1)\n",
        "        X_filled_knn = X_filled_knn.drop(col, axis=1)\n",
        "    else:\n",
        "#Convert to dummy variables.\n",
        "        X_new = pd.get_dummies(X_new, columns=[col], drop_first=True)\n",
        "        X_filled_knn = pd.get_dummies(X_filled_knn, columns=[col], drop_first=True)\n",
        "\n",
        "def handle_unreasonable_values(df):\n",
        "    for column in df.select_dtypes(include=['number']).columns:\n",
        "#Make sure the column is numeric.\n",
        "        if df[column].dtype in [np.int64, np.float64]:\n",
        "#Define lower and upper bounds.\n",
        "            lower_bound = df[column].quantile(0.01) #This is a lower bound, which provides the lowest value that is reasonable given the data.\n",
        "            upper_bound = df[column].quantile(0.99) #This is an upper limit, which provides the highest value that is reasonable.\n",
        "#Replace unreasonable values with NaN.\n",
        "            df[column] = df[column].mask((df[column] < lower_bound) | (df[column] > upper_bound))\n",
        "    return df\n",
        "\n",
        "X_new = handle_unreasonable_values(X_new) #Dealing with abnormal values.\n",
        "X_filled_knn = handle_unreasonable_values(X_filled_knn) #Dealing with abnormal values.\n",
        "\n",
        "\n",
        "print(\"The table X_new after Dealing with abnormal values\",\"\\n\")\n",
        "print(X_new.describe(),\"\\n\")\n",
        "print(\"Data of missing values ​​of X_new\")\n",
        "print(X_new.isnull().sum().to_string(),\"\\n\")\n",
        "\n",
        "print(\"The table X_filled_knn after Dealing with abnormal values\",\"\\n\")\n",
        "print(X_filled_knn.describe())\n",
        "print(\"Data of missing values ​​of X_filled_knn\",\"\\n\")\n",
        "print(X_filled_knn.isnull().sum().to_string(),\"\\n\")\n",
        "\n",
        "#Completion of missing values by Simple Imputer.\n",
        "X_new =fill_missing_values_simple(X_new)\n",
        "print(\"Missing Values Count after using Simple Imputer:\")\n",
        "print(X_new.isnull().sum().to_string(), \"\\n\")\n",
        "\n",
        "#Completion of missing values by KNN Imputer.\n",
        "X_filled_knn= fill_missing_values_knn(X_filled_knn)\n",
        "print(\"Missing Values Count after using KNN Imputer:\")\n",
        "print(X_filled_knn.isnull().sum().to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wwqPhmnr39ZM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9z_xzOwc3996"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m4fiJ5Mq3-L5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqsoO5XOjaqd"
      },
      "source": [
        "#4. Train test split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v_IudXzjaYW"
      },
      "outputs": [],
      "source": [
        "#your code here:\n",
        "X_train_mean, X_test_mean, y_train_mean, y_test_mean = train_test_split(X_new, y, stratify=y,test_size=0.2, random_state = 123)\n",
        "X_train_KNN, X_test_KNN, y_train_KNN, y_test_KNN = train_test_split( X_filled_knn, y,stratify=y, test_size=0.2, random_state = 123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdbJRpF8IsY8"
      },
      "source": [
        "#5. Preprocessing (for both imputed datasets):\n",
        "a. standardize or normalize the data\n",
        "\n",
        "b. print visual representation of the y variable (the output/label variable) or/and value counts of the two categories to test if the data is imbalanced.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzahU-AlJV3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d02fbaef-0fbf-4cf2-cd59-58b9f75f1923"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts in the mean-imputed training set:\n",
            "class\n",
            "1    23740\n",
            "0    19488\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts in the KNN-imputed training set:\n",
            "class\n",
            "1    23740\n",
            "0    19488\n",
            "Name: count, dtype: int64\n",
            "class\n",
            "1    29675\n",
            "0    24360\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "#chatGPT  is used in order to maintain consistency and readability of the code\n",
        "#5a\n",
        "scaler_mean = MinMaxScaler()\n",
        "X_train_mean_scaled_df = scaler_mean.fit_transform(X_train_mean)\n",
        "X_test_mean_scaled_norm_df = scaler_mean.transform(X_test_mean)\n",
        "\n",
        "scaler_knn = MinMaxScaler()\n",
        "X_train_knn_scaled_df = scaler_knn.fit_transform(X_train_KNN)\n",
        "X_test_KNN_scaled_norm_df = scaler_knn.transform(X_test_KNN)\n",
        "\n",
        "#chatGPT is used to print the charts\n",
        "#5b\n",
        "#Visual representation and value counts for y variable to check for imbalance.\n",
        "plt.figure(figsize=(6, 4))\n",
        "mushroom = pd.Series(y_train_mean).value_counts()\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(mushroom.index.map({1: 'Poisonous', 0: 'Not Poisonous'}), mushroom.values, color=['pink', 'cyan']) # Bar plot for class distribution (mean imputed dataset)\n",
        "plt.title('Class Distribution in Training Set (Mean Imputed)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "#Print value counts of each class in the training set.\n",
        "class_counts_mean = y_train_mean.value_counts()\n",
        "print(\"Class counts in the mean-imputed training set:\")\n",
        "print(class_counts_mean)\n",
        "\n",
        "#Do the same for the KNN imputed dataset.\n",
        "plt.figure(figsize=(6, 4))\n",
        "mushroom = pd.Series(y_train_mean).value_counts()\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(mushroom.index.map({1:'Poisonous', 0: 'Not Poisonous'}), mushroom.values, color=['pink', 'cyan']) #Bar plot for class distribution (KNN imputed dataset).\n",
        "plt.title('Class Distribution in Training Set (KNN Imputed)')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "#Print value counts of each class in the KNN-imputed training set.\n",
        "class_counts_knn = y_train_KNN.value_counts()\n",
        "print(\"Class counts in the KNN-imputed training set:\")\n",
        "print(class_counts_knn)\n",
        "\n",
        "#Check the count of each category.\n",
        "category_counts = y.value_counts()\n",
        "\n",
        "#Print the count of each category.\n",
        "print(category_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46Pr9C1CLnlL"
      },
      "source": [
        "#6. Choose one balancing method and perform it on your data.\n",
        "\n",
        "Verbally explain the logic behind the chosen balancing metohd, how does it work?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here, if balancing is requierd:\n",
        "#We consulted about this question in the chat because there was no severe imbalance, so we were unsure how to proceed.\n",
        "#Create a SMOTE object.\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "#Balance the data using SMOTE.\n",
        "X_train_mean_balanced, y_train_mean_balanced = smote.fit_resample(X_train_mean_scaled_df, y_train_mean)\n",
        "X_train_knn_balanced, y_train_knn_balanced = smote.fit_resample(X_train_knn_scaled_df , y_train_mean)\n",
        "\n",
        "#chatGPT is used to print the chart\n",
        "#Display the distribution after balancing using SMOTE.\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x=y_train_mean_balanced, palette='pastel')\n",
        "plt.title('Class Distribution in Training Set After SMOTE')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks([0, 1], ['Not Poisonous', 'Poisonous'])\n",
        "plt.show()\n",
        "\n",
        "#Count each category after balancing.\n",
        "class_counts_mean_balanced = pd.Series(y_train_mean_balanced).value_counts()\n",
        "print(\"Class counts after SMOTE (Mean Imputed):\")\n",
        "print(class_counts_mean_balanced)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "ES9Iz9QcuaPL",
        "outputId": "c57ebb0f-2a13-4465-bf01-00b6c25a565b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-96834bf2e13a>:13: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x=y_train_mean_balanced, palette='pastel')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class counts after SMOTE (Mean Imputed):\n",
            "class\n",
            "1    23740\n",
            "0    23740\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B1KVYl3LYTM"
      },
      "source": [
        "#Your answer here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD תשובה בקובץ"
      ],
      "metadata": {
        "id": "S0KQr_irBgGR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p32CMu4SNEQb"
      },
      "source": [
        "#7. Training models (for both imputed datasets):\n",
        "**a.** choose three classification algorithms, two must be either random forest or XGBoost or catboost or LGBM, and apply the algorithms on the train set.  \n",
        "\n",
        "**b.** apply hyperparameter tuning on at least two algorithms using gridsearchCV function.\n",
        "\n",
        "**c.** print the best hyperparameters for the three models.\n",
        "\n",
        "Reminder, if the tuned model is named \"grid\" than to get the best hyperparameter combination use the following function:\n",
        "\n",
        "\n",
        "```\n",
        "grid.best_params_\n",
        "```\n",
        "\n",
        "\n",
        "**d.** Veraverbally explain: what is the role of the chosen hyperparmeters in the learning algorithms? How did you choose the values for the optimization? (in 3-4 lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here:\n",
        "#Model 1- Random Forest.\n",
        "#chatGPT used in order to maintain consistency and readability of the code. Adjustments were made in the parameters according to attempts to improve the indices\n",
        "#Define the parameter grid for Random Forest.\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [10, 20,30,40,50], #Number of trees in the forest.\n",
        "    'max_depth': [7,8,9,10,11], #Maximum depth of the tree.\n",
        "}\n",
        "\n",
        "#Initialize the model.\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "#Initialize GridSearchCV.\n",
        "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, refit=True, n_jobs=-1, verbose=3)\n",
        "\n",
        "#Fit GridSearchCV for mean-imputed data.\n",
        "grid_search_rf.fit(X_train_mean_balanced,y_train_mean_balanced)\n",
        "\n",
        "#Print the best parameters and best score for Random Forest.\n",
        "print(\"Best parameters for Random Forest (mean-imputed data):\", grid_search_rf.best_params_)\n",
        "\n",
        "grid_search_rf_knn = GridSearchCV(estimator=rf, param_grid=param_grid_rf, refit=True, n_jobs=-1, verbose=3)\n",
        "grid_search_rf_knn.fit(X_train_knn_balanced, y_train_knn_balanced)\n",
        "print(\"Best parameters for Random Forest (KNN-imputed data):\", grid_search_rf_knn.best_params_)\n",
        "\n",
        "#Model 2- CatBoost.\n",
        "scaler = MinMaxScaler()\n",
        "catboost_model = CatBoostClassifier(random_state=123, silent=True)\n",
        "steps = [(\"scaler\", scaler), (\"classifier\", catboost_model)]\n",
        "pipeline = Pipeline(steps)\n",
        "#Defining the hyperparameters.\n",
        "cat_param_grid = {'classifier__depth':[6,7,8,9,10], 'classifier__iterations':[70,80,100,120,150],}\n",
        "\n",
        "cat_grid_search = GridSearchCV(pipeline, param_grid=cat_param_grid, cv=2, n_jobs=-1, verbose=3)\n",
        "cat_grid_search.fit(X_train_mean_balanced, y_train_mean_balanced)\n",
        "print(\"Best parameters for CatBoost (mean-imputed data):\", cat_grid_search.best_params_)\n",
        "\n",
        "cat_grid_search_knn = GridSearchCV(pipeline, param_grid=cat_param_grid, cv=2, n_jobs=-1, verbose=3)\n",
        "cat_grid_search_knn.fit(X_train_knn_balanced, y_train_knn_balanced)\n",
        "print(\"Best parameters for CatBoost (KNN-imputed data):\", cat_grid_search_knn.best_params_)\n",
        "\n",
        "#We used ChatGPT to assist in implementing this algorithm.\n",
        "#An algorithm not taught in class Gradient Boosting.\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "param_grid_gb = {\n",
        "    'n_estimators':[100, 200],  #Count the trees.\n",
        "    'learning_rate':[0.01, 0.1, 0.2]  #Learning Rate.\n",
        "}\n",
        "\n",
        "grid_search_gb_mean = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb, cv=5, n_jobs=-1, verbose=3)\n",
        "grid_search_gb_mean.fit(X_train_mean_balanced, y_train_mean_balanced)\n",
        "print(\"Best parameters for Gradient Boosting (mean-imputed data):\", grid_search_gb_mean.best_params_)\n",
        "\n",
        "grid_search_gb_knn = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb, cv=5, n_jobs=-1, verbose=3)\n",
        "grid_search_gb_knn.fit(X_train_knn_balanced, y_train_knn_balanced)\n",
        "print(\"Best parameters for Gradient Boosting (KNN-imputed data):\", grid_search_gb_knn.best_params_)"
      ],
      "metadata": {
        "id": "Ky1KehS5am3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69fa0aa9-eb26-4c09-cc49-f167711f15cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
            "  _data = np.array(data, dtype=dtype, copy=copy,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Random Forest (mean-imputed data): {'max_depth': 11, 'n_estimators': 50}\n",
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "Best parameters for Random Forest (KNN-imputed data): {'max_depth': 11, 'n_estimators': 50}\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
            "Best parameters for CatBoost (mean-imputed data): {'classifier__depth': 10, 'classifier__iterations': 120}\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
            "Best parameters for CatBoost (KNN-imputed data): {'classifier__depth': 10, 'classifier__iterations': 150}\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "Best parameters for Gradient Boosting (mean-imputed data): {'learning_rate': 0.2, 'n_estimators': 200}\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "Best parameters for Gradient Boosting (KNN-imputed data): {'learning_rate': 0.2, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySInCwHzY6kG"
      },
      "source": [
        "#Your answer here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD תשובה בקובץ"
      ],
      "metadata": {
        "id": "n3uJjU31MtP6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbNQJ0fakULJ"
      },
      "source": [
        "#8. Train a neural network on both imputed datasets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here:\n",
        "#Model 1: Define the neural network.\n",
        "model_mean = Sequential()\n",
        "model_mean.add(Input(shape=(8,))) #Input layer with 8 features.\n",
        "\n",
        "model_knn = Sequential()\n",
        "model_knn.add(Input(shape=(8,))) #Input layer with 8 features.\n",
        "\n",
        "#First hidden layer with 64 neurons + input layer.\n",
        "model_mean.add(Dense(64, activation='relu'))\n",
        "\n",
        "model_knn.add(Dense(64, activation='relu'))\n",
        "\n",
        "#Second hidden layer with 32 neurons, includes Dropout for regularization.\n",
        "model_mean.add(Dropout(0.5))\n",
        "model_mean.add(Dense(32, activation='relu'))\n",
        "\n",
        "model_knn.add(Dropout(0.5))\n",
        "model_knn.add(Dense(32, activation='relu'))\n",
        "\n",
        "#Output layer with sigmoid activation for binary classification.\n",
        "model_mean.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_knn.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#compile the model: using Adam (Adaptive Moment Estimation) optimizer, binary cross-entropy loss, and accuracy metric.\n",
        "model_mean.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_knn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Train on the second dataset.\n",
        "history_mean=model_mean.fit(X_train_mean_scaled_df,y_train_mean_balanced, epochs=35, batch_size=33, validation_split=0.2)\n",
        "\n",
        "history_knn = model_knn.fit(X_train_knn_scaled_df, y_train_knn_balanced, epochs=35, batch_size=33, validation_split=0.2)\n",
        "\n",
        "#Display the models summary.\n",
        "model_mean.summary()\n",
        "\n",
        "model_knn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F5Rk7N5sC0F8",
        "outputId": "6b5f0fe7-ce53-4e49-c089-68fc0c5e2dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5876 - loss: 0.6638 - val_accuracy: 0.6585 - val_loss: 0.6063\n",
            "Epoch 2/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6535 - loss: 0.6181 - val_accuracy: 0.6947 - val_loss: 0.5770\n",
            "Epoch 3/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6778 - loss: 0.5905 - val_accuracy: 0.7141 - val_loss: 0.5542\n",
            "Epoch 4/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6886 - loss: 0.5755 - val_accuracy: 0.7270 - val_loss: 0.5368\n",
            "Epoch 5/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7024 - loss: 0.5622 - val_accuracy: 0.7427 - val_loss: 0.5216\n",
            "Epoch 6/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7026 - loss: 0.5556 - val_accuracy: 0.7469 - val_loss: 0.5091\n",
            "Epoch 7/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5405 - val_accuracy: 0.7614 - val_loss: 0.4973\n",
            "Epoch 8/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5332 - val_accuracy: 0.7597 - val_loss: 0.4916\n",
            "Epoch 9/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7273 - loss: 0.5274 - val_accuracy: 0.7659 - val_loss: 0.4770\n",
            "Epoch 10/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.5210 - val_accuracy: 0.7512 - val_loss: 0.4844\n",
            "Epoch 11/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7364 - loss: 0.5142 - val_accuracy: 0.7708 - val_loss: 0.4636\n",
            "Epoch 12/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.5090 - val_accuracy: 0.7646 - val_loss: 0.4684\n",
            "Epoch 13/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5070 - val_accuracy: 0.7686 - val_loss: 0.4564\n",
            "Epoch 14/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.5028 - val_accuracy: 0.7785 - val_loss: 0.4550\n",
            "Epoch 15/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7487 - loss: 0.4981 - val_accuracy: 0.7794 - val_loss: 0.4522\n",
            "Epoch 16/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7483 - loss: 0.4966 - val_accuracy: 0.7910 - val_loss: 0.4403\n",
            "Epoch 17/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7448 - loss: 0.4966 - val_accuracy: 0.7828 - val_loss: 0.4455\n",
            "Epoch 18/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7492 - loss: 0.4930 - val_accuracy: 0.7805 - val_loss: 0.4451\n",
            "Epoch 19/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7494 - loss: 0.4927 - val_accuracy: 0.7913 - val_loss: 0.4312\n",
            "Epoch 20/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7536 - loss: 0.4836 - val_accuracy: 0.7983 - val_loss: 0.4273\n",
            "Epoch 21/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7610 - loss: 0.4782 - val_accuracy: 0.7917 - val_loss: 0.4305\n",
            "Epoch 22/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7588 - loss: 0.4820 - val_accuracy: 0.7982 - val_loss: 0.4318\n",
            "Epoch 23/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.4794 - val_accuracy: 0.8081 - val_loss: 0.4183\n",
            "Epoch 24/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7602 - loss: 0.4762 - val_accuracy: 0.8009 - val_loss: 0.4226\n",
            "Epoch 25/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7581 - loss: 0.4823 - val_accuracy: 0.7968 - val_loss: 0.4251\n",
            "Epoch 26/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7610 - loss: 0.4765 - val_accuracy: 0.8067 - val_loss: 0.4165\n",
            "Epoch 27/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7645 - loss: 0.4741 - val_accuracy: 0.7991 - val_loss: 0.4233\n",
            "Epoch 28/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7614 - loss: 0.4718 - val_accuracy: 0.7842 - val_loss: 0.4312\n",
            "Epoch 29/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7677 - loss: 0.4688 - val_accuracy: 0.8093 - val_loss: 0.4067\n",
            "Epoch 30/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7661 - loss: 0.4688 - val_accuracy: 0.8007 - val_loss: 0.4179\n",
            "Epoch 31/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.4694 - val_accuracy: 0.8081 - val_loss: 0.4094\n",
            "Epoch 32/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7694 - loss: 0.4604 - val_accuracy: 0.8044 - val_loss: 0.4121\n",
            "Epoch 33/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7714 - loss: 0.4643 - val_accuracy: 0.8035 - val_loss: 0.4116\n",
            "Epoch 34/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.4639 - val_accuracy: 0.7998 - val_loss: 0.4106\n",
            "Epoch 35/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.4649 - val_accuracy: 0.8149 - val_loss: 0.4010\n",
            "Epoch 1/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5900 - loss: 0.6641 - val_accuracy: 0.6653 - val_loss: 0.6069\n",
            "Epoch 2/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6575 - loss: 0.6116 - val_accuracy: 0.6911 - val_loss: 0.5684\n",
            "Epoch 3/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6807 - loss: 0.5842 - val_accuracy: 0.7083 - val_loss: 0.5389\n",
            "Epoch 4/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7002 - loss: 0.5611 - val_accuracy: 0.7401 - val_loss: 0.5154\n",
            "Epoch 5/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.5495 - val_accuracy: 0.7497 - val_loss: 0.4968\n",
            "Epoch 6/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7130 - loss: 0.5395 - val_accuracy: 0.7641 - val_loss: 0.4818\n",
            "Epoch 7/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5244 - val_accuracy: 0.7730 - val_loss: 0.4710\n",
            "Epoch 8/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7316 - loss: 0.5162 - val_accuracy: 0.7819 - val_loss: 0.4629\n",
            "Epoch 9/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5100 - val_accuracy: 0.7849 - val_loss: 0.4567\n",
            "Epoch 10/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7446 - loss: 0.5061 - val_accuracy: 0.7845 - val_loss: 0.4507\n",
            "Epoch 11/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7523 - loss: 0.4952 - val_accuracy: 0.7887 - val_loss: 0.4441\n",
            "Epoch 12/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7472 - loss: 0.4977 - val_accuracy: 0.7955 - val_loss: 0.4354\n",
            "Epoch 13/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7535 - loss: 0.4898 - val_accuracy: 0.8000 - val_loss: 0.4281\n",
            "Epoch 14/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7569 - loss: 0.4871 - val_accuracy: 0.8009 - val_loss: 0.4251\n",
            "Epoch 15/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7625 - loss: 0.4797 - val_accuracy: 0.8040 - val_loss: 0.4182\n",
            "Epoch 16/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7638 - loss: 0.4749 - val_accuracy: 0.8065 - val_loss: 0.4097\n",
            "Epoch 17/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7762 - loss: 0.4655 - val_accuracy: 0.8073 - val_loss: 0.4048\n",
            "Epoch 18/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7709 - loss: 0.4626 - val_accuracy: 0.8108 - val_loss: 0.4049\n",
            "Epoch 19/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7701 - loss: 0.4614 - val_accuracy: 0.8189 - val_loss: 0.3963\n",
            "Epoch 20/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7753 - loss: 0.4545 - val_accuracy: 0.8250 - val_loss: 0.3937\n",
            "Epoch 21/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7750 - loss: 0.4581 - val_accuracy: 0.8270 - val_loss: 0.3865\n",
            "Epoch 22/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7791 - loss: 0.4501 - val_accuracy: 0.8247 - val_loss: 0.3885\n",
            "Epoch 23/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7733 - loss: 0.4534 - val_accuracy: 0.8287 - val_loss: 0.3822\n",
            "Epoch 24/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7787 - loss: 0.4482 - val_accuracy: 0.8339 - val_loss: 0.3817\n",
            "Epoch 25/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7811 - loss: 0.4469 - val_accuracy: 0.8329 - val_loss: 0.3786\n",
            "Epoch 26/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7886 - loss: 0.4376 - val_accuracy: 0.8399 - val_loss: 0.3759\n",
            "Epoch 27/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7862 - loss: 0.4377 - val_accuracy: 0.8367 - val_loss: 0.3755\n",
            "Epoch 28/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7857 - loss: 0.4365 - val_accuracy: 0.8326 - val_loss: 0.3754\n",
            "Epoch 29/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7878 - loss: 0.4371 - val_accuracy: 0.8321 - val_loss: 0.3741\n",
            "Epoch 30/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7932 - loss: 0.4309 - val_accuracy: 0.8384 - val_loss: 0.3707\n",
            "Epoch 31/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7884 - loss: 0.4318 - val_accuracy: 0.8418 - val_loss: 0.3655\n",
            "Epoch 32/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7914 - loss: 0.4311 - val_accuracy: 0.8426 - val_loss: 0.3664\n",
            "Epoch 33/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.4295 - val_accuracy: 0.8436 - val_loss: 0.3636\n",
            "Epoch 34/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.4298 - val_accuracy: 0.8322 - val_loss: 0.3684\n",
            "Epoch 35/35\n",
            "\u001b[1m1048/1048\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7948 - loss: 0.4268 - val_accuracy: 0.8328 - val_loss: 0.3687\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,069\u001b[0m (31.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,069</span> (31.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,689\u001b[0m (10.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,689</span> (10.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,380\u001b[0m (21.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,380</span> (21.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,069\u001b[0m (31.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,069</span> (31.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,689\u001b[0m (10.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,689</span> (10.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,380\u001b[0m (21.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,380</span> (21.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrdwJiEdkzP4"
      },
      "source": [
        "#Explain the structure of the network: how many layers? what layers? how manny weights/coefficients/parameters are there in your network? (2-3 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKUQFV4blHX1"
      },
      "source": [
        "#Your answer here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WORD תשובה בקובץ"
      ],
      "metadata": {
        "id": "5vnJh9QKbqmK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXR9AHo9Y3gJ"
      },
      "source": [
        "#9. a. Predict the y variable on both the train set and the test set (for both imputed datasets and for both algorithms - 16 predictions in total):\n",
        "2 imputed datasets * 4 models * (train+test)\n",
        "\n",
        "and print the accuracy of each prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGXWpYFLZyHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2fdb2bb-ec72-4a38-c082-161b13c5d0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report for Random Forest on Mean-Imputed Data (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.93     19488\n",
            "           1       0.98      0.89      0.93     23740\n",
            "\n",
            "    accuracy                           0.93     43228\n",
            "   macro avg       0.93      0.93      0.93     43228\n",
            "weighted avg       0.93      0.93      0.93     43228\n",
            "\n",
            "\n",
            "Classification Report for Random Forest on Mean-Imputed Data (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91      4872\n",
            "           1       0.97      0.89      0.92      5935\n",
            "\n",
            "    accuracy                           0.92     10807\n",
            "   macro avg       0.92      0.92      0.92     10807\n",
            "weighted avg       0.92      0.92      0.92     10807\n",
            "\n",
            "\n",
            "Classification Report for Random Forest on KNN-Imputed Data (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.96      0.92     19488\n",
            "           1       0.97      0.89      0.93     23740\n",
            "\n",
            "    accuracy                           0.92     43228\n",
            "   macro avg       0.92      0.93      0.92     43228\n",
            "weighted avg       0.93      0.92      0.92     43228\n",
            "\n",
            "\n",
            "Classification Report for Random Forest on KNN-Imputed Data (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.95      0.91      4872\n",
            "           1       0.96      0.88      0.92      5935\n",
            "\n",
            "    accuracy                           0.91     10807\n",
            "   macro avg       0.91      0.92      0.91     10807\n",
            "weighted avg       0.92      0.91      0.91     10807\n",
            "\n",
            "\n",
            "Classification Report for CatBoost on Mean-Imputed Data (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     19488\n",
            "           1       0.99      0.98      0.98     23740\n",
            "\n",
            "    accuracy                           0.98     43228\n",
            "   macro avg       0.98      0.98      0.98     43228\n",
            "weighted avg       0.98      0.98      0.98     43228\n",
            "\n",
            "\n",
            "Classification Report for CatBoost on Mean-Imputed Data (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.97      4872\n",
            "           1       0.98      0.97      0.97      5935\n",
            "\n",
            "    accuracy                           0.97     10807\n",
            "   macro avg       0.97      0.97      0.97     10807\n",
            "weighted avg       0.97      0.97      0.97     10807\n",
            "\n",
            "\n",
            "Classification Report for CatBoost on KNN-Imputed Data (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95     19488\n",
            "           1       0.97      0.96      0.96     23740\n",
            "\n",
            "    accuracy                           0.96     43228\n",
            "   macro avg       0.96      0.96      0.96     43228\n",
            "weighted avg       0.96      0.96      0.96     43228\n",
            "\n",
            "\n",
            "Classification Report for CatBoost on KNN-Imputed Data (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94      4872\n",
            "           1       0.96      0.95      0.95      5935\n",
            "\n",
            "    accuracy                           0.95     10807\n",
            "   macro avg       0.95      0.95      0.95     10807\n",
            "weighted avg       0.95      0.95      0.95     10807\n",
            "\n",
            "\n",
            "Classification Report for Gradient Boosting on Mean-Imputed Data (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90     19488\n",
            "           1       0.94      0.89      0.91     23740\n",
            "\n",
            "    accuracy                           0.91     43228\n",
            "   macro avg       0.91      0.91      0.91     43228\n",
            "weighted avg       0.91      0.91      0.91     43228\n",
            "\n",
            "\n",
            "Classification Report for Gradient Boosting on Mean-Imputed Data (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.92      0.89      4872\n",
            "           1       0.93      0.88      0.91      5935\n",
            "\n",
            "    accuracy                           0.90     10807\n",
            "   macro avg       0.90      0.90      0.90     10807\n",
            "weighted avg       0.90      0.90      0.90     10807\n",
            "\n",
            "\n",
            "Classification Report for Gradient Boosting on KNN-Imputed Data (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91     19488\n",
            "           1       0.95      0.89      0.92     23740\n",
            "\n",
            "    accuracy                           0.91     43228\n",
            "   macro avg       0.91      0.91      0.91     43228\n",
            "weighted avg       0.91      0.91      0.91     43228\n",
            "\n",
            "\n",
            "Classification Report for Gradient Boosting on KNN-Imputed Data (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.93      0.90      4872\n",
            "           1       0.94      0.89      0.91      5935\n",
            "\n",
            "    accuracy                           0.91     10807\n",
            "   macro avg       0.90      0.91      0.91     10807\n",
            "weighted avg       0.91      0.91      0.91     10807\n",
            "\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\n",
            "Classification Report for Neural Network on Mean-Imputed Data (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.86      0.81     19488\n",
            "           1       0.87      0.78      0.82     23740\n",
            "\n",
            "    accuracy                           0.82     43228\n",
            "   macro avg       0.82      0.82      0.82     43228\n",
            "weighted avg       0.82      0.82      0.82     43228\n",
            "\n",
            "\n",
            "Classification Report for Neural Network on Mean-Imputed Data (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.86      0.81      4872\n",
            "           1       0.87      0.78      0.82      5935\n",
            "\n",
            "    accuracy                           0.82     10807\n",
            "   macro avg       0.82      0.82      0.82     10807\n",
            "weighted avg       0.82      0.82      0.82     10807\n",
            "\n",
            "\u001b[1m1351/1351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
            "\u001b[1m338/338\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "Classification Report for Neural Network on KNN-Imputed Data (Training Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.82      0.82     19488\n",
            "           1       0.85      0.85      0.85     23740\n",
            "\n",
            "    accuracy                           0.83     43228\n",
            "   macro avg       0.83      0.83      0.83     43228\n",
            "weighted avg       0.83      0.83      0.83     43228\n",
            "\n",
            "\n",
            "Classification Report for Neural Network on KNN-Imputed Data (Test Set):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.81      0.81      4872\n",
            "           1       0.85      0.85      0.85      5935\n",
            "\n",
            "    accuracy                           0.83     10807\n",
            "   macro avg       0.83      0.83      0.83     10807\n",
            "weighted avg       0.83      0.83      0.83     10807\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "#chatGPT  was used to create the function to improve code readability and prevent code duplication\n",
        "#Function to generate classification reports for each model.\n",
        "def generate_reports(model, X_train, y_train, X_test, y_test, model_name, dataset_name):\n",
        "\n",
        "#Predicting on the training set.\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    print(f\"\\nClassification Report for {model_name} on {dataset_name} (Training Set):\")\n",
        "    print(classification_report(y_train, y_train_pred))\n",
        "\n",
        "#Predicting on the test set.\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    print(f\"\\nClassification Report for {model_name} on {dataset_name} (Test Set):\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "#Example usage of the function with specific models and datasets.\n",
        "generate_reports(grid_search_rf.best_estimator_,X_train_mean_scaled_df, y_train_mean,X_test_mean_scaled_norm_df, y_test_mean, \"Random Forest\", \"Mean-Imputed Data\")\n",
        "generate_reports(grid_search_rf.best_estimator_, X_train_knn_scaled_df, y_train_KNN, X_test_KNN_scaled_norm_df, y_test_KNN, \"Random Forest\", \"KNN-Imputed Data\")\n",
        "generate_reports(cat_grid_search.best_estimator_, X_train_mean_scaled_df, y_train_mean, X_test_mean_scaled_norm_df, y_test_mean, \"CatBoost\", \"Mean-Imputed Data\")\n",
        "generate_reports(cat_grid_search.best_estimator_, X_train_knn_scaled_df, y_train_KNN, X_test_KNN_scaled_norm_df, y_test_KNN, \"CatBoost\", \"KNN-Imputed Data\")\n",
        "generate_reports(grid_search_gb_mean.best_estimator_, X_train_mean_scaled_df, y_train_mean, X_test_mean_scaled_norm_df, y_test_mean, \"Gradient Boosting\", \"Mean-Imputed Data\")\n",
        "generate_reports(grid_search_gb_knn.best_estimator_, X_train_knn_scaled_df, y_train_KNN, X_test_KNN_scaled_norm_df, y_test_KNN, \"Gradient Boosting\", \"KNN-Imputed Data\")\n",
        "\n",
        "#Prediction on the Neural network .We use chatGPT to convert each of the categories:\n",
        "#Prediction and report generation for Neural Network models.\n",
        "#Neural network predictions on mean-imputed data.\n",
        "y_train_mean_nn_pred = (model_mean.predict(X_train_mean_scaled_df) > 0.5).astype(\"int32\")\n",
        "y_test_mean_nn_pred = (model_mean.predict(X_test_mean_scaled_norm_df) > 0.5).astype(\"int32\")\n",
        "print(\"\\nClassification Report for Neural Network on Mean-Imputed Data (Training Set):\")\n",
        "print(classification_report(y_train_mean, y_train_mean_nn_pred))\n",
        "print(\"\\nClassification Report for Neural Network on Mean-Imputed Data (Test Set):\")\n",
        "print(classification_report(y_test_mean, y_test_mean_nn_pred))\n",
        "\n",
        "#Neural network predictions on KNN-imputed data.\n",
        "y_train_knn_nn_pred = (model_knn.predict(X_train_knn_scaled_df) > 0.5).astype(\"int32\")\n",
        "y_test_knn_nn_pred = (model_knn.predict(X_test_KNN_scaled_norm_df) > 0.5).astype(\"int32\")\n",
        "print(\"\\nClassification Report for Neural Network on KNN-Imputed Data (Training Set):\")\n",
        "print(classification_report(y_train_KNN, y_train_knn_nn_pred))\n",
        "print(\"\\nClassification Report for Neural Network on KNN-Imputed Data (Test Set):\")\n",
        "print(classification_report(y_test_KNN, y_test_knn_nn_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q70fd0FZzqS"
      },
      "source": [
        "#b. Based on the accuracies of the predictions, verbally explain which model resulted with the best outcome with consideration to over-fitting, under-fitting and proper-fitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8EIHUuGa5Cu"
      },
      "source": [
        "#Your answer here:\n",
        "WORD תשובה בקובץ\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjsR7CqOaRnC"
      },
      "source": [
        "#Print the classification_report of the test set using the best model and verbally explain another quality measure of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqPM-0PVa1Ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dee3534-63e6-4962-cc7f-371d93132d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Test Set) for Best Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91      4872\n",
            "           1       0.97      0.89      0.92      5935\n",
            "\n",
            "    accuracy                           0.92     10807\n",
            "   macro avg       0.92      0.92      0.92     10807\n",
            "weighted avg       0.92      0.92      0.92     10807\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "best_model = grid_search_rf.best_estimator_\n",
        "\n",
        "#Predict on the test set.\n",
        "y_pred_test = best_model.predict(X_test_mean_scaled_norm_df)\n",
        "\n",
        "#Print classification report for the test set.\n",
        "print(\"Classification Report (Test Set) for Best Model:\")\n",
        "print(classification_report(y_test_mean, y_pred_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyUVqCG6a5mq"
      },
      "source": [
        "#Your answer here:\n",
        "WORD תשובה בקובץ\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjlVS3N9mITn"
      },
      "source": [
        "#Part B:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkXSaeKKmK-D"
      },
      "source": [
        "#10. Data preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTJaRDNTmXu6"
      },
      "source": [
        "#Upload the second table (for regression analysis):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxnogzcqmVBY"
      },
      "outputs": [],
      "source": [
        "#your code here:\n",
        "df_ApartmentPrices= pd.read_csv(\"Apartment Prices.csv\")\n",
        "df_ApartmentPricesCo = df_ApartmentPrices.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6cVe6RjmVBZ"
      },
      "source": [
        "#Read the file into a pandas data frame:\n",
        "Split your data to:\n",
        "\n",
        "a. X: the feature matrix\n",
        "\n",
        "b. y: the label vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Yt0dPZJmVBa"
      },
      "outputs": [],
      "source": [
        "#your code here:\n",
        "x_aprt=df_ApartmentPricesCo.drop('PRICE (GEL)',axis=1)\n",
        "y_aprt=df_ApartmentPricesCo['PRICE (GEL)']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5atIA5pm6Z_"
      },
      "source": [
        "#10.A. Check for missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd-y5pz7m6aB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f9b2df-e2ab-45fc-d37e-0bdc62daf5c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before filling:\n",
            "CityPart                   0\n",
            "Area                       0\n",
            "Rooms                      0\n",
            "Bedrooms                 235\n",
            "Floor                      1\n",
            "MaxFloor                   1\n",
            "LastFloor                  0\n",
            "Status                     4\n",
            "Condition                503\n",
            "Electrical Points        596\n",
            "Heating                 2098\n",
            "Natural Gas                4\n",
            "Bed                        0\n",
            "Stove (Gas/Electric)       0\n",
            "Table                      0\n",
            "Refrigerator               0\n",
            "Chairs                     0\n",
            "Oven                       0\n",
            "Air Conditioner            0\n",
            "Washing Machine            0\n",
            "Sofa                       0\n",
            "Dishwasher                 0\n",
            "PRICE (GEL)                0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "print(\"Missing values before filling:\")\n",
        "print(df_ApartmentPricesCo.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXy2Hq7dm6aB"
      },
      "source": [
        "#10.B. Impute the missing values using two different methods and assign the imputed output datasets into variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-brL9oXm6aC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab12daa-fd5d-48cc-a369-26d13431d51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CityPart                0\n",
            "Area                    0\n",
            "Rooms                   0\n",
            "Bedrooms                0\n",
            "Floor                   0\n",
            "MaxFloor                0\n",
            "LastFloor               0\n",
            "Status                  0\n",
            "Condition               0\n",
            "Electrical Points       0\n",
            "Heating                 0\n",
            "Natural Gas             0\n",
            "Bed                     0\n",
            "Stove (Gas/Electric)    0\n",
            "Table                   0\n",
            "Refrigerator            0\n",
            "Chairs                  0\n",
            "Oven                    0\n",
            "Air Conditioner         0\n",
            "Washing Machine         0\n",
            "Sofa                    0\n",
            "Dishwasher              0\n",
            "PRICE (GEL)             0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-acab979860e8>:13: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  df_ApartmentPricesCo[col] = df_ApartmentPricesCo[col].fillna(method='ffill')\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "#Identify columns with missing values.\n",
        "missing_cols = df_ApartmentPricesCo.columns[df_ApartmentPricesCo.isnull().any()].tolist()\n",
        "\n",
        "#Handling missing values.\n",
        "for col in missing_cols:\n",
        "#Check if the column is numeric.\n",
        "    if df_ApartmentPricesCo[col].dtype in ['float64', 'int64']:\n",
        "#Fill numeric columns with the mean value.\n",
        "        df_ApartmentPricesCo[col] = df_ApartmentPricesCo[col].fillna(df_ApartmentPricesCo[col].mean())\n",
        "    else:\n",
        "#Fill non-numeric columns with the last non-null value.\n",
        "        df_ApartmentPricesCo[col] = df_ApartmentPricesCo[col].fillna(method='ffill')\n",
        "\n",
        "#Check the number of missing values after filling.\n",
        "missing_values = df_ApartmentPricesCo.isnull().sum()\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl6vefQem6aC"
      },
      "source": [
        "#10.C. Convert categorical features to dummy variables if number of categories is lower than 5, otherwise remove from data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTrcdLfQm6aD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c63e5fb-3cdf-4ab9-c3de-78f21292c2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Area        Rooms     Bedrooms        Floor     MaxFloor  \\\n",
            "count    7258.000000  7258.000000  7023.000000  7257.000000  7257.000000   \n",
            "mean      116.794622     2.886746     1.805639     6.974921    11.914152   \n",
            "std      1875.877409     1.052626     0.829334     5.027288     6.302284   \n",
            "min        14.500000     1.000000     1.000000     1.000000     1.000000   \n",
            "25%        55.500000     2.000000     1.000000     3.000000     8.000000   \n",
            "50%        72.000000     3.000000     2.000000     6.000000    11.000000   \n",
            "75%        98.000000     3.000000     2.000000    10.000000    15.000000   \n",
            "max    120240.000000    10.000000    10.000000    36.000000    80.000000   \n",
            "\n",
            "         LastFloor  Electrical Points  Natural Gas          Bed  \\\n",
            "count  7258.000000        6662.000000  7254.000000  7258.000000   \n",
            "mean      0.151832           1.230561     0.726496     0.305594   \n",
            "std       0.358883           0.484849     0.445788     0.460690   \n",
            "min       0.000000           1.000000     0.000000     0.000000   \n",
            "25%       0.000000           1.000000     0.000000     0.000000   \n",
            "50%       0.000000           1.000000     1.000000     0.000000   \n",
            "75%       0.000000           1.000000     1.000000     1.000000   \n",
            "max       1.000000           3.000000     1.000000     1.000000   \n",
            "\n",
            "       Stove (Gas/Electric)        Table  Refrigerator       Chairs  \\\n",
            "count           7258.000000  7258.000000   7258.000000  7258.000000   \n",
            "mean               0.323230     0.307936      0.318958     0.274180   \n",
            "std                0.467742     0.461672      0.466105     0.446131   \n",
            "min                0.000000     0.000000      0.000000     0.000000   \n",
            "25%                0.000000     0.000000      0.000000     0.000000   \n",
            "50%                0.000000     0.000000      0.000000     0.000000   \n",
            "75%                1.000000     1.000000      1.000000     1.000000   \n",
            "max                1.000000     1.000000      1.000000     1.000000   \n",
            "\n",
            "              Oven  Air Conditioner  Washing Machine         Sofa   Dishwasher  \n",
            "count  7258.000000      7258.000000      7258.000000  7258.000000  7258.000000  \n",
            "mean      0.308074         0.300496         0.104023     0.314412     0.316203  \n",
            "std       0.461729         0.458505         0.305312     0.464313     0.465025  \n",
            "min       0.000000         0.000000         0.000000     0.000000     0.000000  \n",
            "25%       0.000000         0.000000         0.000000     0.000000     0.000000  \n",
            "50%       0.000000         0.000000         0.000000     0.000000     0.000000  \n",
            "75%       1.000000         1.000000         0.000000     1.000000     1.000000  \n",
            "max       1.000000         1.000000         1.000000     1.000000     1.000000  \n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "for col in x_aprt.select_dtypes(include=['object']).columns:\n",
        "\n",
        "#Check if the number of unique values in the column is greater than 4.\n",
        "    if x_aprt[col].nunique() > 4:\n",
        "       x_aprt.drop(col, axis=1, inplace=True)\n",
        "    else:\n",
        "#Drop the column if it has more than 4 unique values.\n",
        "       x_aprt = pd.get_dummies(x_aprt, columns=[col], drop_first=True)\n",
        "\n",
        "#Check and handle unrealistic values in the dataset.\n",
        "print(x_aprt.describe())\n",
        "for col in x_aprt.select_dtypes(include=['number']).columns:\n",
        "\n",
        "#Define lower and upper bounds based on the 1st and 99th percentiles.\n",
        "    lower_bound = x_aprt[col].quantile(0.01)\n",
        "    upper_bound = x_aprt[col].quantile(0.99)\n",
        "\n",
        "#Replace values outside the bounds with NaN.\n",
        "    x_aprt[col] = np.where((x_aprt[col] < lower_bound) | (x_aprt[col] > upper_bound), np.nan, x_aprt[col])\n",
        "\n",
        "#Fill in missing values created from replacing unrealistic values with the mean of each column.\n",
        "x_aprt.fillna(x_aprt.mean(), inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItZzsxOGm6aD"
      },
      "source": [
        "#10.D. Train test split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4n5XisBm6aE"
      },
      "outputs": [],
      "source": [
        "#your code here:\n",
        "X_train_aprt, X_test_aprt, y_train_aprt, y_test_aprt = train_test_split(x_aprt,y_aprt, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWbyIGVvm6aE"
      },
      "source": [
        "#10.D. standardize or normalize the data\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWrtiYf9m6aE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fbc1596-dfbe-4f09-8a26-c6f6dc4d47c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after the normalization: /n\n",
            "          Area     Rooms  Bedrooms     Floor  MaxFloor  LastFloor  \\\n",
            "0     0.223730  0.369126  1.000000  0.227273  0.133333        1.0   \n",
            "1     0.056769  0.200000  0.000000  0.636364  0.933333        0.0   \n",
            "2     0.279476  0.400000  0.333333  0.263628  0.933333        0.0   \n",
            "3     0.279476  0.400000  0.333333  0.263628  0.933333        0.0   \n",
            "4     0.423581  0.600000  0.666667  0.772727  0.933333        0.0   \n",
            "...        ...       ...       ...       ...       ...        ...   \n",
            "7253  0.257642  0.600000  0.666667  0.227273  0.266667        0.0   \n",
            "7254  0.213974  0.400000  0.333333  0.272727  0.200000        0.0   \n",
            "7255  0.969432  1.000000  0.666667  0.272727  0.200000        0.0   \n",
            "7256  0.196507  0.200000  0.000000  0.136364  0.233333        0.0   \n",
            "7257  0.593886  0.800000  0.666667  0.500000  0.366667        0.0   \n",
            "\n",
            "      Electrical Points  Natural Gas  Bed  Stove (Gas/Electric)  Table  \\\n",
            "0              1.000000     1.000000  0.0                   0.0    1.0   \n",
            "1              0.000000     0.000000  0.0                   0.0    0.0   \n",
            "2              0.000000     0.000000  0.0                   0.0    0.0   \n",
            "3              0.000000     0.000000  0.0                   0.0    0.0   \n",
            "4              0.000000     0.000000  0.0                   0.0    0.0   \n",
            "...                 ...          ...  ...                   ...    ...   \n",
            "7253           0.500000     0.000000  0.0                   0.0    0.0   \n",
            "7254           0.115281     0.726496  0.0                   0.0    0.0   \n",
            "7255           0.115281     0.726496  0.0                   0.0    0.0   \n",
            "7256           0.115281     0.726496  0.0                   0.0    0.0   \n",
            "7257           0.115281     0.726496  0.0                   0.0    0.0   \n",
            "\n",
            "      Refrigerator  Chairs  Oven  Air Conditioner  Washing Machine  Sofa  \\\n",
            "0              0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "1              0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "2              0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "3              0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "4              0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "...            ...     ...   ...              ...              ...   ...   \n",
            "7253           0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "7254           0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "7255           0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "7256           0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "7257           0.0     0.0   0.0              0.0              0.0   0.0   \n",
            "\n",
            "      Dishwasher  Status_Old Constructed  Status_Under Construction  \n",
            "0            0.0                     0.0                        0.0  \n",
            "1            0.0                     0.0                        1.0  \n",
            "2            0.0                     0.0                        1.0  \n",
            "3            0.0                     0.0                        1.0  \n",
            "4            0.0                     0.0                        1.0  \n",
            "...          ...                     ...                        ...  \n",
            "7253         0.0                     0.0                        1.0  \n",
            "7254         0.0                     0.0                        0.0  \n",
            "7255         0.0                     0.0                        0.0  \n",
            "7256         0.0                     0.0                        0.0  \n",
            "7257         0.0                     0.0                        0.0  \n",
            "\n",
            "[7258 rows x 20 columns]\n",
            "0       4619070\n",
            "1        149441\n",
            "2        234757\n",
            "3        234757\n",
            "4        347789\n",
            "         ...   \n",
            "7253     346252\n",
            "7254     271570\n",
            "7255    1072702\n",
            "7256     257992\n",
            "7257     638190\n",
            "Name: PRICE (GEL), Length: 7258, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "mms = MinMaxScaler()\n",
        "x_aprt_norm= mms.fit_transform(x_aprt)\n",
        "x_aprt_norm = pd.DataFrame(x_aprt_norm, columns=x_aprt.columns)\n",
        "print(\"after the normalization: /n\")\n",
        "print(x_aprt_norm)\n",
        "print (y_aprt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx4FjmJgnP92"
      },
      "source": [
        "#11. Train a linear regression model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jmihk-OGoAJk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "3a00cb7f-b808-4ec5-c14c-46a9aeee2968"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#your code here:\n",
        "#Function to calculate Mean Absolute Percentage Error.\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "#Create a Linear Regression model.\n",
        "regressor = LinearRegression()\n",
        "\n",
        "#Fit the model on the training data.\n",
        "regressor.fit(X_train_aprt, y_train_aprt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfRk86hInXlI"
      },
      "source": [
        "#12. On both the train set and the test set, predict the values based on the linear regression model and print the following measures:\n",
        "\n",
        "\t*  R^2\n",
        "\t*  Root Mean Square Error (RMSE)\n",
        "\t*  Mean Absolut Error (MAE)\n",
        "\t*  Mean Absolut Percent Error (MAPE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_ZELtEloBfl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248c206e-e045-4067-bfa1-c6b5d87f5836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model performance for testing set:\n",
            "R-squared is -0.0016703850931609754\n",
            "RMSE is 2297895.1105726887\n",
            "MAE score is 282577.92031437973\n",
            "MAPE score is 196.22620369890257 \n",
            "\n",
            "The model performance for training set:\n",
            "R-squared is 0.011754846542810893\n",
            "RMSE is 3759425.0669974457\n",
            "MAE score is 283811.30916414753\n",
            "MAPE score is 17636.35427142282\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "#Predict results on the test set.\n",
        "y_pred_aprt = regressor.predict(X_test_aprt)\n",
        "\n",
        "#model evaluation for test set.\n",
        "Lin_r2=r2_score(y_test_aprt, y_pred_aprt) #Calculate R-squared.\n",
        "RMSE = (np.sqrt(mean_squared_error(y_test_aprt, y_pred_aprt))) #Calculate Root Mean Squared Error.\n",
        "MAE= mean_absolute_error(y_test_aprt, y_pred_aprt) #Calculate Mean Absolute Error.\n",
        "MAPE=mean_absolute_percentage_error(y_test_aprt, y_pred_aprt) #Calculate Mean Absolute Percentage Error.\n",
        "\n",
        "#Display the model performance metrics for the test set.\n",
        "print(\"The model performance for testing set:\")\n",
        "print('R-squared is {}'.format(Lin_r2))\n",
        "print('RMSE is {}'.format(RMSE))\n",
        "print('MAE score is {}'.format(MAE))\n",
        "print('MAPE score is {}'.format(MAPE) ,\"\\n\")\n",
        "\n",
        "#Evaluate the model on the training set.\n",
        "y_pred_train_aprt = regressor.predict(X_train_aprt) #Predict on the training set.\n",
        "lin_r2_train=r2_score(y_train_aprt, y_pred_train_aprt) #Calculate R-squared for training set.\n",
        "RMSE_train = (np.sqrt(mean_squared_error(y_train_aprt, y_pred_train_aprt))) #Calculate RMSE for training set.\n",
        "MAE_train= mean_absolute_error(y_train_aprt, y_pred_train_aprt) #Calculate MAE for training set.\n",
        "MAPE_train=mean_absolute_percentage_error(y_train_aprt, y_pred_train_aprt) #Calculate MAPE for training set.\n",
        "\n",
        "#Display the model performance metrics for the training set.\n",
        "print(\"The model performance for training set:\")\n",
        "print('R-squared is {}'.format(lin_r2_train))\n",
        "print('RMSE is {}'.format(RMSE_train))\n",
        "print('MAE score is {}'.format(MAE_train))\n",
        "print('MAPE score is {}'.format(MAPE_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmoF2nk9oFT-"
      },
      "source": [
        "#13. Polynomial regression: follow instruction in the attached documnet."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transform the original features to polynomial features.\n",
        "poly = PolynomialFeatures()\n",
        "X_poly = poly.fit_transform(x_aprt_norm) #Transforming the original features to polynomial features.\n",
        "X_poly_train, X_poly_test, y_poly_train, y_poly_test = train_test_split(X_poly, y_aprt, test_size = 0.2, random_state=123)\n",
        "\n",
        "#Ignore convergence warnings.\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "#Parameter definitions.\n",
        "degrees_to_test = [2 ]#3, 4]  #Polynomial degrees to test. Degree 2 was found to perform best, so higher degrees were skipped.\n",
        "alphas = [0.01, 0.1, 1, 10, 100]  #Alpha values to test.\n",
        "\n",
        "#Dictionary to keep track of the best results\n",
        "best_results = {\n",
        "    'model': None,\n",
        "    'alpha': None,\n",
        "    'degree': None,\n",
        "    'mae': float('inf') #Initialize with infinity to find the minimum MAE.\n",
        "}\n",
        "\n",
        "#Initial data split for train and test sets using a fixed random state.\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_aprt_norm, y_aprt, test_size=0.2, random_state=123)\n",
        "\n",
        "#Loop to evaluate models for each polynomial degree.\n",
        "for degree in degrees_to_test:\n",
        "    for model_type, model in [('Lasso', Lasso()), ('Ridge', Ridge())]:\n",
        "\n",
        "#Define a pipeline with PolynomialFeatures and Lasso/Ridge regression.\n",
        "        pipeline = Pipeline([('poly', PolynomialFeatures(degree=degree, interaction_only=True)),('model', model)])\n",
        "\n",
        "#Grid search to find the best alpha value.\n",
        "        param_grid = {'model__alpha': alphas}\n",
        "        grid_search = GridSearchCV(pipeline, param_grid, scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "#Fit the model and evaluate it.\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "#Calculate MAE for the best alpha and degree found.\n",
        "        mae = -grid_search.best_score_\n",
        "\n",
        "#Update the best results if a lower MAE is found.\n",
        "        if mae < best_results['mae']:\n",
        "            best_results.update({'model': model_type,'alpha': grid_search.best_params_['model__alpha'],'degree': degree,'mae': mae})\n",
        "\n",
        "#Print the best results.\n",
        "print(\"Best Polynomial Degree (d):\", best_results['degree'])\n",
        "print(\"Best Model:\", best_results['model'])\n",
        "print(\"Best Regularization Strength (alpha):\", best_results['alpha'])\n",
        "print(\"Best Mean Absolute Error (MAE): {:.4f}\".format(best_results['mae']))\n",
        "\n",
        "#Function to evaluate model performance metrics.\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    return r2, rmse, mae, mape\n",
        "\n",
        "#Prediction on the training set and the test set.\n",
        "best_model = best_results['model']  #Store the best model type.\n",
        "best_degree = best_results['degree']\n",
        "best_alpha = best_results['alpha']\n",
        "\n",
        "#Build the pipeline with the best settings.\n",
        "pipeline = Pipeline([('poly', PolynomialFeatures(degree=best_degree, interaction_only=True)),('model', Lasso(alpha=best_alpha) if best_model == 'Lasso' else Ridge(alpha=best_alpha))])\n",
        "\n",
        "#Fit the model with the data.\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "#Prediction and performance evaluation on the test set.\n",
        "y_pred_test = pipeline.predict(X_test)\n",
        "r2_test, rmse_test, mae_test, mape_test = evaluate_model(y_test, y_pred_test)\n",
        "\n",
        "print(\"The model performance for the test set:\")\n",
        "print(f'R-squared: {r2_test:.4f}')\n",
        "print(f'RMSE: {rmse_test:.4f}')\n",
        "print(f'MAE: {mae_test:.4f}')\n",
        "print(f'MAPE: {mape_test:.4f}\\n')\n",
        "\n",
        "#Prediction and performance evaluation on the training set.\n",
        "y_pred_train = pipeline.predict(X_train)\n",
        "r2_train, rmse_train, mae_train, mape_train = evaluate_model(y_train, y_pred_train)\n",
        "\n",
        "print(\"The model performance for the training set:\")\n",
        "print(f'R-squared: {r2_train:.4f}')\n",
        "print(f'RMSE: {rmse_train:.4f}')\n",
        "print(f'MAE: {mae_train:.4f}')\n",
        "print(f'MAPE: {mape_train:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T6thS3dYyMo",
        "outputId": "714144ab-0fbd-4da7-e07b-39c3fa8501b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Polynomial Degree (d): 2\n",
            "Best Model: Ridge\n",
            "Best Regularization Strength (alpha): 100\n",
            "Best Mean Absolute Error (MAE): 264633.2870\n",
            "The model performance for the test set:\n",
            "R-squared: 0.0013\n",
            "RMSE: 2307856.3602\n",
            "MAE: 269274.6763\n",
            "MAPE: 63751.5832\n",
            "\n",
            "The model performance for the training set:\n",
            "R-squared: 0.0196\n",
            "RMSE: 3742368.1763\n",
            "MAE: 254802.7434\n",
            "MAPE: 172.3060\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvIm0OEUoUSW"
      },
      "source": [
        "#14. Verbally explain the problem with polynomial transformation of features. How can it be solved? (2-3 sentences)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivECb4FOo9jY"
      },
      "source": [
        "#Your answer here:\n",
        "WORD תשובה בקובץ\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsvLKBFHoqe1"
      },
      "source": [
        "#Verbally explain what are ridge and lasso? when shoud each be used? what's the diffrence between them? (up to 4 sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Aj-zGZNo9_A"
      },
      "source": [
        "#Your answer here:\n",
        "WORD תשובה בקובץ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEsLJp7Fo-kl"
      },
      "source": [
        "#15. Train additional algorithms as specified in the attached document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D1LfRt1pPDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b311fbee-6dbe-477e-ee1f-78576b5b71d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for RandomForest: {'max_depth': None, 'n_estimators': 100}\n",
            "Best parameters for CatBoost: {'depth': 6, 'iterations': 100}\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002143 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 354\n",
            "[LightGBM] [Info] Number of data points in the train set: 5806, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score 425479.408887\n",
            "Performance of RandomForest:\n",
            "Training set:\n",
            "R^2: 0.77, RMSE: 1799476.67, MAE: 85001.22, MAPE: 4657.21\n",
            "Testing set:\n",
            "R^2: 0.01, RMSE: 2280493.25, MAE: 153352.48, MAPE: 115.84\n",
            "Performance of CatBoost:\n",
            "Training set:\n",
            "R^2: 1.00, RMSE: 184409.35, MAE: 98621.08, MAPE: 3817.23\n",
            "Testing set:\n",
            "R^2: -4.05, RMSE: 5160673.40, MAE: 338661.17, MAPE: 185.47\n",
            "Performance of LGBM:\n",
            "Training set:\n",
            "R^2: 0.22, RMSE: 3334324.56, MAE: 192170.73, MAPE: 5971.53\n",
            "Testing set:\n",
            "R^2: -0.03, RMSE: 2326755.76, MAE: 200560.76, MAPE: 154.46\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#your code here:\n",
        "#randomforestRegressor model:\n",
        "RF_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "#Parameter definition for RandomForestRegressor.\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200], #Number of trees in the forest.\n",
        "    'max_depth': [None, 10, 20] #Maximum depth of each tree.\n",
        "}\n",
        "\n",
        "#Performing GridSearchCV to find the best parameters for the RandomForest model.\n",
        "rf_grid_search = GridSearchCV(estimator=RF_model, param_grid=rf_param_grid, cv=5, n_jobs=-1)\n",
        "rf_grid_search.fit(X_train_aprt, y_train_aprt)\n",
        "\n",
        "#Storing the best model based on the grid search results.\n",
        "best_rf_model = rf_grid_search .best_estimator_\n",
        "print(\"Best parameters for RandomForest:\", rf_grid_search.best_params_)\n",
        "\n",
        "#Catboostregressor model:\n",
        "param_grid_cat = {\n",
        "    'iterations': [100, 200], #Number of trees.\n",
        "    'depth': [6, 10] #Depth of trees.\n",
        "}\n",
        "\n",
        "#Defining CatBoostRegressor and performing GridSearchCV to find the best parameters.\n",
        "cat = CatBoostRegressor(random_state=123, verbose=0)\n",
        "cat_search = GridSearchCV(cat, param_grid=param_grid_cat, cv=5, n_jobs=-1)\n",
        "cat_search.fit(X_train_aprt, y_train_aprt)\n",
        "\n",
        "#Storing the best model based on the grid search results.\n",
        "best_cat_model = cat_search.best_estimator_\n",
        "print(\"Best parameters for CatBoost:\", cat_search.best_params_)\n",
        "\n",
        "#LGBMRegressor model.\n",
        "LGBM_model = LGBMRegressor(random_state=123)\n",
        "LGBM_model.fit(X_train_aprt, y_train_aprt)\n",
        "\n",
        "#Defining a dictionary to store the models for later evaluation.\n",
        "models = {'RandomForest': best_rf_model, 'CatBoost': best_cat_model, 'LGBM': LGBM_model}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "#Predicting on the training set.\n",
        "    y_train_pred = model.predict(X_train_aprt)\n",
        "    r2_train, rmse_train, mae_train, mape_train = evaluate_model(y_train_aprt, y_train_pred)\n",
        "\n",
        " #Predicting on the testing set.\n",
        "    y_test_pred = model.predict(X_test_aprt)\n",
        "    r2_test, rmse_test, mae_test, mape_test = evaluate_model(y_test_aprt, y_test_pred)\n",
        "\n",
        "    print(f\"Performance of {model_name}:\")\n",
        "    print(\"Training set:\")\n",
        "    print(f\"R^2: {r2_train:.2f}, RMSE: {rmse_train:.2f}, MAE: {mae_train:.2f}, MAPE: {mape_train:.2f}\")\n",
        "    print(\"Testing set:\")\n",
        "    print(f\"R^2: {r2_test:.2f}, RMSE: {rmse_test:.2f}, MAE: {mae_test:.2f}, MAPE: {mape_test:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JETnIFoUpXdk"
      },
      "source": [
        "#16. Verbally explain: which model is the best? Briefly explain the model predictions outcome in terms of over and under fitting -explain.\n",
        "#Explain each of the 4 error measuers presented and how they coul be interpreted in the context of your data specifically?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjsBNZoxqQVp"
      },
      "source": [
        "#Your answer here:\n",
        "WORD תשובה בקובץ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M573muOoa6Kp"
      },
      "source": [
        "#Good Luck!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}